## Architecture
The high-level architecture of the single-node Pooler system is shown below.
![PowerloomSingleNodeSystem-Overall Architecture drawio (2)-Overall Architecture-Overall Architecture](https://user-images.githubusercontent.com/9114274/207789809-1cb87843-3acb-44fb-ac29-0f4cd66b3400.jpg)

## RabbitMQ Initialization

Just like the name suggests, the `init_rabbitmq.py` file sets up the various queues required for Pooler to function. At the top level, there are two types of queues, exchange queues, and callback queues. 
Callback Queue is consumed by workers to generate the actual snapshot data (see the `callback_modules` folder) to be submitted to Audit Protocol.
Exchange queues are usually used for high-level operations like Epoch notifications etc.

This is a one-time task that users need to do when they run the pooler for the first time (detailed instructions are present in the README.md file).


## System Block Epoch Ticker
The system linear ticker is defined in `system_ticker_linear.py` and is initiated by using `processhub_cmd.py` CLI. It takes an optional `begin` argument which specifies the block from which it needs to start generating epochs. If not specified, it starts from the current block. 

The main role of this process is to generate `epochs` of height `h` (configured in settings.json) in a sliding window fashion and broadcast generated epochs using `epoch-consensus` RabbitMQ queue.

## System Epoch Collator
The system epoch collator is defined in `system_epoch_collator.py`, it consumes the `epoch` generated by `System Block Epoch Ticker` from the `epoch-consensus` queue.
It then first collates (thing of it like processing to add some reorg related data) and then distributes the epochs data to `Epoch Finalizer` using a distributed system tool call [tooz](https://github.com/openstack/tooz).
It is also initiated using `processhub_cmd.py` CLI.

## System Epoch Finalizer
The system epoch finalizer is defined in `system_epoch_finalizer.py`, it coordinates with System Epoch Collater using tooz to get the collated reports and pushes them to `epoch-broadcast` queue.
It is also initiated using `processhub_cmd.py` CLI.

## Epoch Callback Manager
The epoch callback manager is defined in `epoch_broadcast_callback_manager.py` and is also initiated using the `processhub_cmd.py` CLI.
It reads the messages from `epoch-broadcast` queue, adds a little extra helper context like contract_addresses for uniswap v2 pairs, 
sends the messages to relavant routing channels according to topics defined in callback modules (see callback_modules/module_queue_config.json) and pushes the task to `backend-callbacks` queue.

## Process Hub Core
Process Hub Core (defined in `process_hub_core.py`) is the main process manager in Pooler. It in combination with `processhub_cmd.py` is used to start and manage `System Block Epoch Ticker`, `System Epoch Collator`, `System Epoch Finalizer`, and `Epoch Callback Manager`. Process Hub Core is also responsible for spawing up the worker threads required for processing tasks from the `backend-callbacks` queue. These workers and their configuration is read from `callback_modules/module_queues_config.json`.

## Server
The main FastAPI server and entry point for this module is `core_api.py`, this server is started using a custom Gunicorn handler present in `gunicorn_core_launcher.py`. Doing so provides more flexibility to customize the application and start it using `Pm2`. `core_api.py` provides multiple API endpoints to interact with the snapshotted data in various ways.


## Helpers and Utilities
### Clean Slate
`clean_slate.py` can be used to clean up Redis and IPFS data.

### Process Hub CLI
`processhub_cmd.py` acts as a CLI tool to interact with `process_hub_core`. This CLI is used to start various processes like `EpochCallbackManager` through the `process_hub_core_modules`.

### Exceptions
`exceptions.py` declares custom Exceptions used across the project.

### File Utils
`file_utils.py` contains helper functions like reading from and writing to `JSON` files.

### RPC Helper
`rpc_helper.py` contains helper functions to help interact with RPC endpoints like making batch_calls (calling multiple contract functions in a single RPC call) etc.

### Redis Utilities
`redis_conn.py` contains utility and helper functions for Redis pool setup and `redis_keys.py` contains functions to generate all the `keys` that are used in Redis across the entire module.

### Other Utilities
`rate_limiter.py` and `utility_functions.py` contain helper functions for rate limiting using Redis and some other generic utilities.

`launch_process_hub_core.py` is used to initialize necessary RabbitMQ queues and start the `process_hub_core` with a custom title (for cleaner process management using Pm2) 
